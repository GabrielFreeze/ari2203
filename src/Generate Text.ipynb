{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed11e17",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a8656",
   "metadata": {},
   "source": [
    "To generate text, the user needs to give a starting word. Then the program attempts to find a probable word that would usually follow the previous word / couple of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4687e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae17fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(os.getcwd(),'..','data','korpus')\n",
    "vanilla = os.path.join(folder,'ngram','vanilla')\n",
    "unk = os.path.join(folder,'ngram','unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeca8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(folder,'norm_korpus_clean.csv'))\n",
    "words = df['Word'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74213b",
   "metadata": {},
   "source": [
    "###### Algorithm Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559facf",
   "metadata": {},
   "source": [
    "If the ngram supplied is a unigram, then text generation doesn't need to look at the previous word and it essential becomes a random guess from the top 50 words. If the ngram is not a unigram, then we find in the ngram all words that start with the n-1 previous words. Then we choose a word to generate from the top 50 most probable words.\n",
    "\n",
    "If the model supplied is Vanilla, the program may break. This is because if there doesn't exist an instance of the n-1 previous words in the ngram, then the program doesn't have a word to generate.\n",
    "\n",
    "If the model supplied is Laplace and the n-1 previous words do not appear in the ngram, Laplace smoothing considers all sequences of words to be matched with every other word at least once. Hence in this case, Laplace transform essentially chooses a random word, since all available probabilities are the same.\n",
    "\n",
    "If the model supplied is UNK and the n-1 previous words do not appear in the ngram, the unkown words are replaced with the \\<UNK> token. The program then re-attempts to find an instance of an ngram that starts with the new modified history. If an instance is still not found, since the \\<UNK> model was also Laplace Smoothed, then a random word is taken from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3888f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(phrase:str, model:str, n:int):\n",
    "    \n",
    "    if model == 'vanilla' or model == 'laplace':\n",
    "        model_path = vanilla\n",
    "    elif model == 'unk': \n",
    "        model_path = unk\n",
    "    else: raise Exception('Model does not exist!')\n",
    "    \n",
    "    print(\"Loading Models: \",end='')\n",
    "    if n in [1,2,3]:\n",
    "        xgrams = ['unigram.csv','bigram.csv','trigram.csv']\n",
    "        ngram_path = xgrams[n-1]\n",
    "        \n",
    "        xgrams_types = ['Unigram','Bigram','Trigram']\n",
    "        ngram_type = xgrams_types[n-1]\n",
    "        \n",
    "        df_ngram = pd.read_csv(os.path.join(model_path, ngram_path))\n",
    "        \n",
    "        ngrams = df_ngram[ngram_type].unique()\n",
    "        \n",
    "        if n != 1:\n",
    "            prev_df_gram = pd.read_csv(os.path.join(model_path,xgrams[n-2]))\n",
    "            prev_ngrams = prev_df_gram[xgrams_types[n-2]].unique()\n",
    "            \n",
    "    else: raise Exception('Choose Unigram, Bigram or Trigram!')\n",
    "    print('[OK]')\n",
    "    print('Generating Sentence...')\n",
    "    \n",
    "    generated_word = \"\"\n",
    "    \n",
    "    if n == 1:\n",
    "        top_words = df_ngram['Probability'].astype(float).nlargest(50).index\n",
    "    \n",
    "    while generated_word != '</s>':\n",
    "        phrase += ' '\n",
    "        if n == 1:\n",
    "            generated_word = df_ngram.iat[top_words[randint(0,49)],0]\n",
    "            phrase += generated_word\n",
    "        \n",
    "        else:\n",
    "            #Get previous words\n",
    "            tokens = phrase.split(' ')\n",
    "            history = ';'.join(tokens[len(tokens)-n:len(tokens)-1])\n",
    "            \n",
    "            #Find most probable words that follow previous words\n",
    "            if model == 'vanilla' or history in prev_ngrams:\n",
    "                top_words = df_ngram[df_ngram[ngram_type].str.startswith(history)]['Probability'].astype(float).nlargest(50).index\n",
    "            \n",
    "            #If there is no match for the history, then laplace smoothing comes in.\n",
    "            #Laplace smoothing will ensure that there is an occurence with the previous history at least once \n",
    "            #with every other word. Hence the next word becomes essentially a random guess.\n",
    "            else:\n",
    "                if model == 'unk':\n",
    "                    #Replace unkown words with UNK and recalculate accordingly\n",
    "                    new_history = ['<UNK>' if w not in words else w for w in history.split(';')]\n",
    "                    history = ';'.join(new_history)\n",
    "                    \n",
    "                    #Attempt to find any nrgams with the <UNK> modified history\n",
    "                    if history in prev_ngrams:\n",
    "                        top_words = df_ngram[df_ngram[ngram_type].str.startswith(history)]['Probability'].astype(float).nlargest(50).index\n",
    "                    \n",
    "                    #If there is still no combination with the UNK words, then take a random guess due to laplace smoothing\n",
    "                    else: top_words = [randint(0,len(df_ngram)-1)] \n",
    "                        \n",
    "                    \n",
    "                else: top_words = [randint(0,len(df_ngram)-1)]\n",
    "            \n",
    "            \n",
    "            #Pick a random word from the top 50.\n",
    "            generated_word = df_ngram.iat[top_words[randint(0,len(top_words)-1)],0].split(';')[-1]\n",
    "            #Add to current phrase\n",
    "            phrase += generated_word\n",
    "            \n",
    "    return phrase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d6a3b",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674966e1",
   "metadata": {},
   "source": [
    "Let's consider the same starting phrase <i>Jiena kont</i> to generate text across all different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6831c5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 132 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Jiena kont dawn kif li L- xi L- kien l- kif jkun qed qed għall- għal jew l- fl- fuq ma' id- kull se fuq minn is- xi ma l- aktar lil din wara ma' oħra b' biex fuq L- biex se dawn hemm L- il- kien is- jkun id- il- it- hemm jew sena ir- biex lill- lil hemm L- din oħra tiegħu hemm jkun tal- dawn lill- lill- dan ma fl- jkun sena u dwar aktar xi sena ma se ir- ħafna <s> b' dwar fuq minn b' xi għal lill- għall- sena f' fuq oħra mill- lil 1 <s> li kien jew din il- ħafna xi u se xi tiegħu oħra minn meta 1 għal <s> sena meta dan dan f' jew jkun L- it- dwar biex kull dawn L- ta' qed kull biex li sena biex tal- kull il- f' għal tiegħu se L- kien għal u f' jew tiegħu tiegħu is- is- ħafna dawn fil- fuq għall- lil b' ir- hemm it- meta ma f' kif f' jew sena ir- fil- meta ħafna minn kif lill- fuq tal- dawn b' fuq jkun <s> is- <s> fuq biex xi fuq tiegħu fil- ma' is- b' aktar it- ta' ir- 1 l- Il- aktar lill- fl- Il- lill- dwar minn tal- f' tal- f' dak kif meta dan jew lill- fl- ma' ta' <s> se u ir- jkun dak xi </s>\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'vanilla', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93daa6",
   "metadata": {},
   "source": [
    "As we can see from the vanilla unigram generation, the generated text is giberrish. We note that the majority of the words are articles and prepositions. This makes sense since the top most 50 common words in the corpus are as such. We should also realise that if the end of sentence token was not among the top 50 common words, then the generation would never stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc7a066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 5.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jiena kont li Mark Tulius Cicerus 106 kif jiġi mill- familja li </s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'vanilla', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3592a",
   "metadata": {},
   "source": [
    "Switching to a bigram model, we can immediately see some improvements. We know that that are words that are not among the top 50, such as <b>familja</b> and <b>Mark</b> which is a name. Hence we can confirm that the program is not taking random guesses.\n",
    "\n",
    "The bigram <b>mill- familja</b> makes sense. In the corpus you would expect to find nouns to follow articles, and not anything else. The bigram <b>jigi mill-</b> also makes sense, as <b>jigi</b> is often used to mean <b>he is related to</b> rather than <b>he came</b>.\n",
    "\n",
    "However the sentence doesn't seem to indicate any particular flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0cec302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Jiena;kont\n",
      "kont;għadni\n",
      "għadni;skolastiku\n",
      "skolastiku;hu\n",
      "hu;kien\n",
      "kien;jagħmel\n",
      "Wall time: 8.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jiena kont għadni skolastiku hu kien jagħmel </s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'vanilla', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e694eb",
   "metadata": {},
   "source": [
    "The following sentence, although still not completely coherent, still indicates the best flow. Most notably the word <b>għandi</b>. Given that the current context is the first person (<b>Jien</b>) it would make sense to see verbs that are in the first person, unlike <b>għandu</b> or <b>għandhom</b>.\n",
    "\n",
    "This implies that the trigram is working since <b>kont</b> doesn't encode any information on the speaker, unlike <b>Jiena</b>.\n",
    "\n",
    "The same reasoning goes for <b>jagħmel</b>. The word is considering the previous 2 words <b>hu kien</b> which are in the masculine third person.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2de4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 142 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jiena kont sena jew din meta se u se dawn li oħra dak lil is- minn </s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'laplace', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c78168",
   "metadata": {},
   "source": [
    "For Laplace unigram, the output isn't very different form that of vanilla unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5a22d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 5.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Jiena kont f' pajjiżi mhux talli qatt x- xewqa sempliċi ikunu determinati f' isem philodendron </s>\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'laplace', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d4137",
   "metadata": {},
   "source": [
    "Once again we with the bigram, we also see that the words have more coherent structure. Most notably the bigram <b>x- xewqa</b>. The article is dictating that the following noun should start with an <b>x</b> which it does. Similairly the preposition <b>f'</b> always follows a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557721c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 49.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Jiena kont naħseb jien faqqiegħ li qed jiġri biex jitla' fuq \\xad vapur irid juri bil- fatti ta' dak hawn Malta kontra l- Iskozja ssir membru tal- unjoni monetarja u ekonomika il- fatt dwar kif għandu jitqies bħala persuna b' saħħitha f' dan 1 għan tiġi l- Ħadd li għadda Malta għelbet lill- goalkeeper avversarju għal skor ta' 5 sena ma ukoll ma bħala mistenni </s>\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'laplace', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8eca723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 47.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Jiena kont dwar dak u għall- fil- lil ma' meta L- il- fil- minn fuq wara ma wara dwar dak meta jkun dak dan </s>\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'unk', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69bda3",
   "metadata": {},
   "source": [
    "The UNK unigram gives the same result as the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b48d91ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 7.95 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jiena kont għaliex jekk huwa parti fejn dawn ġew <UNK> of l- ħajja normali stabbilit għall- finanzi illi ruħha kull u għal bl- ATT XX </s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'unk', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5dbbb",
   "metadata": {},
   "source": [
    "Once again we see that prepositions are always followed by nouns. Moreover, we see the generation of the \\<UNK> token, proving that the \\<UNK> model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485f16a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n",
      "Wall time: 24.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Jiena kont għadni żgħir niġri isfel stess lit- tarbija għaċ- ċajt Offi mifhum mozzjoni Abu trattament ażjenda men mhux ikunu ma' grupp żgħażagħ jorganizzaw numru ta' pazjenti bl- iskizofrenija kif ukoll fl- Istitut Mediterranju u fid- dekasteru tagħha </s>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_text('Jiena kont', 'unk', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a716f05",
   "metadata": {},
   "source": [
    "Once again we see that <b>għadni</b> respects the context of the previous 2 words. Consonants that are \"<b>xemxin</b>\" are also respected in the articles <b>lit- tarbija</b> and <b>għaċ- ċajt</b>. You would expect to find the phrase <b>grupp żgħażagħ jorganizzaw numru ta'</b> while reading an article about a charity event for example. However since the trigram only considers up to 2 words for context, it seems that the word <b>pazjenti</b> was taken from a different article about mental health institutions such as Mount Carmel. You would also expect to find <b>numru ta' pazjenti bl- iskizofrenija</b> in an article talking about hospital patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b569e79",
   "metadata": {},
   "source": [
    "Let's explore some more examples from the UNK model, since it seems to give the most accuracte answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68668dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Il- Laburisti wkoll riedu l- permess mill- Ministru ta' qabel fis- 26 u 27 ta' Diċembru l- ġenituri kienu ġew trasferiti lill- Awtorità dik l- era </s>\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('Il- Laburisti', 'unk', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe6277",
   "metadata": {},
   "source": [
    "The generated sentence above gives insight on the pronounciation of numbers in the maltese language. <b>fis- 26</b> shows that even though the number doesn't start with the letter <b>s</b>, speech information is still encoded within the korpus.\n",
    "\n",
    "We should also note that <b>fis- 26</b> meant that that <b>26</b> was representing a date, and hence the phrase was <b> fis- 26 u 27 ta' Diċembru</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03623a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"In- Nazzjonalisti qatt ma ltqajt ma' qaddisa ferħana Chiara kienet mistiedna għall- festival tal- inbid </s>\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('In- Nazzjonalisti', 'unk', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720dcfa",
   "metadata": {},
   "source": [
    "A notable phrase is <b>Chiara kienet mistiedna għall- festival tal- inbid</b>. The ngram encodes the information that Chiara is a female name and hence the words <b>kienet mistiedna</b> follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a7ea8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nhar it- Tnejn 10 ta' Lulju 1994 li jistabbillixxi </s>\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('Nhar it-', 'unk', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd760e",
   "metadata": {},
   "source": [
    "Going over the date idea, the phrase <b>Nhar it- </b> would lead the text generation to list out a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f335c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models: [OK]\n",
      "Generating Sentence...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Għawdex huwa servizz skond in- nomeklatura tal- Komunità għandu jiġi sottomess il- parteċipant </s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('Għawdex huwa', 'unk', 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ari2203-venv",
   "language": "python",
   "name": "ari2203-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
