{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "db847749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ae2599d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(os.getcwd(),'..','data','korpus')\n",
    "vanilla = os.path.join(os.getcwd(),'..','data','korpus','ngram','vanilla')\n",
    "unk = os.path.join(os.getcwd(),'..','data','korpus','ngram','unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7783750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models: [OK]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6688119602932157e-07"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def linear_interpolation(sentence:str, model:str):\n",
    "\n",
    "    if model == 'vanilla' or model == 'laplace':\n",
    "        model_path = vanilla\n",
    "    elif model == 'unk': \n",
    "        model_path = unk\n",
    "    else: raise Exception('Model does not exist!')\n",
    "        \n",
    "    #Load ngrams for the model chosen\n",
    "    print('Loading models: ', end='')\n",
    "    uni = pd.read_csv(os.path.join(model_path,'unigram.csv'))\n",
    "    bi = pd.read_csv(os.path.join(model_path,'bigram.csv'))\n",
    "    tri = pd.read_csv(os.path.join(model_path,'trigram.csv'))\n",
    "    print('[OK]')\n",
    "    \n",
    "    #Calculate size of korpus. (Number of words)\n",
    "    if model != 'vanilla':\n",
    "        path = os.path.join(folder,'norm_korpus_clean.csv')\n",
    "        korpus_size = sum(1 for _ in open(path, encoding='utf-8'))    \n",
    "    \n",
    "    words = sentence.split(' ')\n",
    "    word_count = len(words)\n",
    "    \n",
    "    if word_count < 3:\n",
    "        raise Exception('Sentence must have at least 3 words')\n",
    "    \n",
    "    #Get a numpy array of n-grams\n",
    "    uni_words = uni['Unigram'].to_numpy()\n",
    "    bi_words  = bi ['Bigram' ].to_numpy()\n",
    "    tri_words = tri['Trigram'].to_numpy()\n",
    "    \n",
    "    P = 1\n",
    "    \n",
    "    V = len(uni) #Size of the vocabulary\n",
    "    \n",
    "    λ1,λ2,λ3 = 0.1,0.3,0.6\n",
    "      \n",
    "    for i in range(2,word_count):        \n",
    "        uni_word = f'{words[i]}'\n",
    "        bi_word  = f'{words[i-1]};{words[i]}'\n",
    "        tri_word = f'{words[i-2]};{words[i-1]};{words[i]}'\n",
    "        \n",
    "        #Get the probabilities. If the model is vanilla, we don't have to get the laplace smoothed value.\n",
    "        #The function will just run into an IndexError.\n",
    "        P1 = uni[uni['Unigram'] == uni_word].iat[0,2] if model == 'vanilla' or uni_word in uni_words else 1/len(uni_words)\n",
    "        P2 = bi [bi ['Bigram']  == bi_word ].iat[0,2] if model == 'vanilla' or bi_word  in bi_words  else 1/len(bi_words)\n",
    "        P3 = tri[tri['Trigram'] == tri_word].iat[0,2] if model == 'vanilla' or tri_word in tri_words else 1/len(tri_words)\n",
    "        \n",
    "        #If the model is laplace smoothed (UNK or laplace), \n",
    "        #add 1 to the count of the ngram and \n",
    "        #add V to the denominator.\n",
    "        \n",
    "        #The laplace smoothed probability makes use of the normal vanilla probability. \n",
    "        #This is done in order to reduce code complexity and the number of nested if statements.\n",
    "        \n",
    "        if model != 'vanilla':\n",
    "            N = korpus_size\n",
    "            P1 = P1*((N+V)/N) + (1/(N+V))\n",
    "            \n",
    "            #The frequency of the previous word\n",
    "            history = f'{words[i-1]}'\n",
    "            N = uni[uni['Unigram']==history].iat[0,1] if history in uni_words else 1\n",
    "            P2 = P2*((N+V)/N) + (1/(N+V))\n",
    "            \n",
    "            #The frequency of the two previous words\n",
    "            history = f'{words[i-2]};{words[i-1]}'\n",
    "            N = bi[bi['Bigram']==history].iat[0,1] if history in bi_words else 1\n",
    "            P3 = P3*((N+V)/N) + (1/(N+V))\n",
    "        \n",
    "        #Update the current frequency of the sentenece.\n",
    "        P *= λ1*P1 + λ2*P2 + λ3*P3\n",
    "\n",
    "    return P\n",
    "    \n",
    "\n",
    "linear_interpolation('Darba f\\' għalqa sibt teżor', 'unk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
