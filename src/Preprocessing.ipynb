{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccbb0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e56b112a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = os.path.join(os.getcwd(),'..','data','korpus')\n",
    "subjects = ['Academic','Culture','European','Law','News',\n",
    "            'Opinion','Parliament','Religion','Sport']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9504e1",
   "metadata": {},
   "source": [
    "## Removing XML tags from <i>korpus</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8c9f2",
   "metadata": {},
   "source": [
    "All tags except <b>\\<s\\></b> will be removed from the korpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "727c7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'<(?![/]?s).*?>')\n",
    "def clean(text):\n",
    "    return regex.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab5052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malti03.academic.1.txt\n",
      "malti03.culture.1.txt\n",
      "malti03.law.txt\n",
      "malti03.news.1.txt\n",
      "malti03.opinion.1.txt\n",
      "malti03.religion.2.txt\n",
      "malti03.sport.1.txt\n"
     ]
    }
   ],
   "source": [
    "for sbj in subjects:\n",
    "    path = os.path.join(folder,sbj)\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        filepath = os.path.join(path,filename)\n",
    "\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            print(filename)\n",
    "            text = f.read()\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(clean(text))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146385c",
   "metadata": {},
   "source": [
    "## Turning text file into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e26bed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malti03.academic.1.txt\n",
      "malti03.culture.1.txt\n",
      "malti03.law.txt\n",
      "malti03.news.1.txt\n",
      "malti03.opinion.1.txt\n",
      "malti03.religion.2.txt\n",
      "malti03.sport.1.txt\n"
     ]
    }
   ],
   "source": [
    "subjects = ['Academic']\n",
    "\n",
    "for sbj in subjects:\n",
    "    data = []\n",
    "    path = os.path.join(folder,sbj)\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        filepath = os.path.join(path,filename)\n",
    "        \n",
    "        with open(filepath,'r', encoding='utf-8') as f:\n",
    "            print(filename)\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            for l in lines:\n",
    "                d = l.split('\\t')\n",
    "                \n",
    "                #Start and End Token\n",
    "                if len(d) == 1:\n",
    "                    if re.search(r'<s id=\"[0-9]*\">', d[0]): data.append(['<s>','START',None,None])\n",
    "                    elif re.search(r'</s>', d[0]):          data.append(['</s>','END',None,None])\n",
    "                \n",
    "                elif len(d) > 1:\n",
    "                    d[-1] = d[-1][:-1]\n",
    "                    data.append(d)\n",
    "                    \n",
    "    df = pd.DataFrame(data, columns=['Word','POS','Lemma','Root'])\n",
    "    df.to_csv(os.path.join(path,sbj+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad781",
   "metadata": {},
   "source": [
    "## Joining individual csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df8658",
   "metadata": {},
   "source": [
    "We will create 2 versions of korpus.csv. One will simply be all the csv files together while the other will read an equal number of bytes from each file. This is so the frequency counts won't be biased based on the subject of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb41bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic Finished\n",
      "All Finished\n",
      "\n",
      "Academic Finished\n",
      "All Finished\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(folder,'korpus.csv'), 'w', encoding='utf-8') as f1:\n",
    "    for sbj in subjects:\n",
    "        with open(os.path.join(folder,sbj,sbj+'.csv'), 'r', encoding='utf-8') as f2:\n",
    "            f1.write('\\n')\n",
    "            f1.write(f2.read())\n",
    "            print(f'{sbj} Finished')\n",
    "\n",
    "print('All Finished\\n')\n",
    "\n",
    "\n",
    "min_size = min([os.path.getsize(os.path.join(folder,sbj,sbj+'.csv')) for sbj in subjects])\n",
    "\n",
    "#Only read min_length lines from each csv file. \n",
    "\n",
    "with open(os.path.join(folder,'norm_korpus.csv'), 'w', encoding='utf-8') as f1:\n",
    "    for sbj in subjects:\n",
    "        with open(os.path.join(folder,sbj,sbj+'.csv'), 'r', encoding='utf-8') as f2:    \n",
    "            f1.write('\\n')\n",
    "            f1.write(f2.read(min_size))\n",
    "            print(f'{sbj} Finished')\n",
    "\n",
    "print('All Finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7a035",
   "metadata": {},
   "source": [
    "## Exploring Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a8ad084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 155 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  POS\n",
       "0  </s>  END\n",
       "1  </s>  END\n",
       "2  </s>  END\n",
       "3  </s>  END\n",
       "4  </s>  END\n",
       "5  </s>  END\n",
       "6  </s>  END\n",
       "7  </s>  END\n",
       "8  </s>  END\n",
       "9  </s>  END"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#40 million rows\n",
    "df = pd.read_csv(os.path.join(folder,'korpus.csv'),\n",
    "                 usecols=[\"Word\",\"POS\"],\n",
    "                 dtype={\"Word\": \"U\",\"POS\": \"S\"})\n",
    "\n",
    "df_norm = pd.read_csv(os.path.join(folder,'norm_korpus.csv'),\n",
    "                      usecols=[\"Word\",\"POS\"],\n",
    "                      dtype={\"Word\": \"U\",\"POS\": \"S\"})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62ff14",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e312aca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['END'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28dba331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 212 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Maltese Tagset: https://mlrs.research.um.edu.mt/resources/malti03/tagset30.html\n",
    "\n",
    "df = df.drop(df[df['POS']=='X-PUN'].index) #Punctuation\n",
    "# df = df.drop(df[df['POS']=='X-DIG'].index) #Digits\n",
    "# df = df.drop(df[df['POS']=='X-ENG'].index) #English\n",
    "# df = df.drop(df[df['POS']=='X-FOR'].index) #Foreign\n",
    "# df = df.drop(df[df['POS']=='X-ABV'].index) #Abbreviations\n",
    "df = df.drop(df[df['POS']=='X-BOR'].index) #Gibberish\n",
    "df = df.drop(df[df['POS']=='INT'].index)   #Interjections\n",
    "\n",
    "\n",
    "df_norm = df_norm.drop(df_norm[df_norm['POS']=='X-PUN'].index) #Punctuation\n",
    "# df_norm = df_norm.drop(df_norm[df_norm['POS']=='X-DIG'].index) #Digits\n",
    "# df_norm = df_norm.drop(df_norm[df_norm['POS']=='X-ENG'].index) #English\n",
    "# df_norm = df_norm.drop(df_norm[df_norm['POS']=='X-FOR'].index) #Foreign\n",
    "# df_norm = df_norm.drop(df_norm[df_norm['POS']=='X-ABV'].index) #Abbreviations\n",
    "df_norm = df_norm.drop(df_norm[df_norm['POS']=='X-BOR'].index) #Gibberish\n",
    "df_norm = df_norm.drop(df_norm[df_norm['POS']=='INT'].index)   #Interjections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb97643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Word</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>POS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column_name  percent_missing\n",
       "Word        Word              0.0\n",
       "POS          POS              0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff413c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Word'])\n",
    "df = df.drop(df[df[\"Word\"]=='\"'].index)\n",
    "df = df.drop(df[df[\"Word\"]=='&lt'].index)\n",
    "df = df.drop(df[df[\"Word\"]=='&gt'].index)\n",
    "df = df.drop(df[df[\"Word\"]=='&amp'].index)\n",
    "\n",
    "df_norm = df_norm.dropna(subset=['Word'])\n",
    "df_norm = df_norm.drop(df_norm[df_norm[\"Word\"]=='\"'].index)\n",
    "df_norm = df_norm.drop(df_norm[df_norm[\"Word\"]=='&lt'].index)\n",
    "df_norm = df_norm.drop(df_norm[df_norm[\"Word\"]=='&gt'].index)\n",
    "df_norm = df_norm.drop(df_norm[df_norm[\"Word\"]=='&amp'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41ad4dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Word</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>POS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column_name  percent_missing\n",
       "Word        Word              0.0\n",
       "POS          POS              0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7884382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv(os.path.join(folder,'korpus_clean.csv'), index=False)\n",
    "df_norm.to_csv(os.path.join(folder,'norm_korpus_clean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628b596",
   "metadata": {},
   "source": [
    "## Frequency Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7c2c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(folder, \"korpus_clean.csv\"),\n",
    "                 usecols=[\"Word\",\"POS\"],\n",
    "                 dtype={\"Word\": \"U\",\"POS\": \"S\"})\n",
    "\n",
    "df_norm = pd.read_csv(os.path.join(folder, \"norm_korpus_clean.csv\"),\n",
    "                 usecols=[\"Word\",\"POS\"],\n",
    "                 dtype={\"Word\": \"U\",\"POS\": \"S\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd4aa3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>END</td>\n",
       "      <td>373680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  POS  Frequency\n",
       "0  </s>  END     373680"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all unique words\n",
    "df_frequency = df.value_counts().to_frame()[0].reset_index()\n",
    "df_frequency.columns = ['Word','POS','Frequency']\n",
    "\n",
    "\n",
    "df_normal_frequency = df_norm.value_counts().to_frame()[0].reset_index()\n",
    "df_normal_frequency.columns = ['Word','POS','Frequency']\n",
    "\n",
    "df_frequency.to_csv(os.path.join(folder,'korpus_frequency.csv'), index=False)\n",
    "df_normal_frequency.to_csv(os.path.join(folder,'norm_korpus_frequency.csv'), index=False)\n",
    "\n",
    "df_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac362f",
   "metadata": {},
   "source": [
    "### Viewing most common nouns, adjectives or verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "587743ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, POS, Frequency]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frequency[(df_frequency[\"POS\"] == \"NOUN\")|\n",
    "             (df_frequency[\"POS\"] == \"ADJ\") |\n",
    "             (df_frequency[\"POS\"] == \"VERB\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3db67fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, POS, Frequency]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal_frequency[(df_normal_frequency[\"POS\"] == \"NOUN\")|\n",
    "                    (df_normal_frequency[\"POS\"] == \"ADJ\") |\n",
    "                    (df_normal_frequency[\"POS\"] == \"VERB\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ari2203-venv",
   "language": "python",
   "name": "ari2203-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
